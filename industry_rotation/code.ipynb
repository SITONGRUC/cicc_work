{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a95ba2-5f33-4b54-b6c1-ca02446a05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import simtext\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import datetime\n",
    "import pyecharts\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "# import mplcursors\n",
    "from matplotlib.animation import HTMLWriter\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import SymbolType\n",
    "from pyecharts.commons.utils import JsCode\n",
    "from pyecharts.charts import Line, Scatter, EffectScatter\n",
    "from pyecharts.charts import *\n",
    "from pyecharts.options import *\n",
    "#from util import *\n",
    "#from util.check_utils import dir_check\n",
    "from pyecharts.globals import WarningType\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "#import yfinance as yf\n",
    "#import pyfolio as pf\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "import pymysql, time\n",
    "import cx_Oracle\n",
    "import pymysql\n",
    "import jsdata as js\n",
    "import jieba\n",
    "\n",
    "\n",
    "\n",
    "time_1 = datetime.datetime.now()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.family\"]='SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['lines.markersize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 10\n",
    "plt.rcParams['ytick.major.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['figure.figsize'] = (18,8)   \n",
    "plt.rcParams['figure.dpi'] = 300.0  # 分辨率\n",
    "plt.rcParams['savefig.dpi'] = 300.0  # 图片像素\n",
    "\n",
    "harvest_red = '#a50000'\n",
    "harvest_gray = '#b5b6b6'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "######################################################################\n",
    "os.chdir('./data')\n",
    "######################################################################\n",
    "if 'instantclient_19_5' not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = 'C:\\\\Users\\\\XCZGY\\\\Anaconda3\\\\instantclient_19_5;' + os.environ['PATH']\n",
    "os.environ[\"NLS_LANG\"] = \"SIMPLIFIED CHINESE_CHINA.UTF8\"\n",
    "\n",
    "Oracle_USER = \"jrkj\"\n",
    "Oracle_PWD = 'bpkdJ4_atXFJ7'\n",
    "Oracle_HOST = '10.0.185.137'\n",
    "Oracle_PORT = '1521'\n",
    "Oracle_SERV = 'winddb'\n",
    "\n",
    "conn_addr = Oracle_USER + '/' + Oracle_PWD + '@' + Oracle_HOST + ':' + Oracle_PORT + '/' + Oracle_SERV\n",
    "wind_conn = cx_Oracle.connect(conn_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b55e24-f60a-4bae-ad1e-634875c3ce93",
   "metadata": {},
   "source": [
    "题目数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3386e15-2d15-48c8-8bc3-c8ab0637c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#事先将港股，A股打上标签\n",
    "data_set = pd.read_excel('数据.xlsx',sheet_name ='已有分类A股标的')\n",
    "predict_set = pd.read_excel('数据.xlsx',sheet_name ='待分类港股标的')\n",
    "predict_set['A/H'] = 1\n",
    "data_set['A/H'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed5ab23-b06b-4083-877c-8c81d2174e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#经过测试 单纯使用GICS分类进行处理的效果就不错\n",
    "#而题目中也说明可以加入自己的数据。因此我们引入 wind分类\n",
    "#A股\n",
    "sql = 'select S_INFO_WINDCODE,Wind_ind_code from wind.AShareIndustriesClass where CUR_SIGN = 1'\n",
    "A_wind_indus = pd.read_sql(sql,wind_conn)\n",
    "A_wind_indus['wind一级'] = A_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:4]).astype(int)\n",
    "A_wind_indus['wind二级'] = A_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:6]).astype(int)\n",
    "A_wind_indus['wind三级'] = A_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:8]).astype(int)\n",
    "A_wind_indus = A_wind_indus.rename(columns = {'WIND_IND_CODE':'wind四级','S_INFO_WINDCODE':'股票代码'})\n",
    "A_wind_indus['wind四级'] = A_wind_indus['wind四级'].astype(int)\n",
    "data_set = pd.merge(data_set,A_wind_indus,on = '股票代码',how = 'left')\n",
    "#港股\n",
    "sql = 'select S_INFO_WINDCODE,Wind_ind_code from wind.HKStockWindIndustriesMembers where CUR_SIGN = 1'\n",
    "HK_wind_indus = pd.read_sql(sql,wind_conn)\n",
    "HK_wind_indus['wind一级'] = HK_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:4]).astype(int)\n",
    "HK_wind_indus['wind二级'] = HK_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:6]).astype(int)\n",
    "HK_wind_indus['wind三级'] = HK_wind_indus['WIND_IND_CODE'].apply(lambda x:x[:8]).astype(int)\n",
    "HK_wind_indus = HK_wind_indus.rename(columns = {'WIND_IND_CODE':'wind四级','S_INFO_WINDCODE':'股票代码'})\n",
    "HK_wind_indus['wind四级'] = HK_wind_indus['wind四级'].astype(int)\n",
    "predict_set = pd.merge(predict_set,HK_wind_indus,on = '股票代码',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16c74c3-48f8-47d9-a218-9dbc4a7bc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于存在两地上市 因此我们要检查一下是否给定的数据中存在这种股票\n",
    "sql = 'select S_INFO_WINDCODE as A股证券代码, S_INFO_WINDCOD2 as 港股证券代码  from  wind.SHSZRelatedsecurities'\n",
    "cross_board_list = pd.read_sql(sql,wind_conn)\n",
    "cross_board_list = pd.merge(cross_board_list,\n",
    "                            data_set[['股票代码','一级行业','二级行业']].rename(columns = {'股票代码':'A股证券代码','一级行业':'拟一级行业','二级行业':'拟二级行业'}),\n",
    "                            on = 'A股证券代码',\n",
    "                            how = 'left')\n",
    "predict_set_have_label = pd.merge(predict_set,\n",
    "                       cross_board_list.rename(columns = {'港股证券代码':'股票代码'}),\n",
    "                       on = '股票代码',\n",
    "                       how = 'left')\n",
    "predict_set_have_label = predict_set_have_label[~predict_set_have_label['拟二级行业'].isna()].drop_duplicates()\n",
    "columns_name = ['股票代码', '股票简称', '公司简介', 'GICS一级行业', 'GICS二级行业','A/H',\n",
    "       'GICS三级行业', 'wind四级', 'wind一级', 'wind二级', 'wind三级', 'A股证券代码', '拟一级行业',\n",
    "       '拟二级行业']\n",
    "predict_set_have_label = predict_set_have_label[columns_name]\n",
    "predict_set_have_label=predict_set_have_label.rename(columns = {'拟一级行业':'一级行业','拟二级行业':'二级行业'})[data_set.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f463e69-8ffc-4309-ada8-9e9887d5d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#事实上的确存在。这部分同样可以作为训练集加入训练。或者作为测试集。能够有效避免过拟合\n",
    "predict_set = predict_set[~predict_set['股票代码'].isin(predict_set_have_label['股票代码'])]\n",
    "data_set = data_set.append(predict_set_have_label)\n",
    "# predict_set_have_label.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69f56-33a3-4ab3-bca0-acc2af71a0c9",
   "metadata": {},
   "source": [
    "预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90ab378-163d-45e3-9f4e-3d87d50910de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set_1 = data_set[['股票代码', '股票简称', '公司简介', '一级行业',\n",
    "                       '二级行业','A/H', 'GICS一级行业', 'GICS二级行业','GICS三级行业'\n",
    "                      , 'wind一级', 'wind二级', 'wind三级','wind四级']]\n",
    "# 一级指标明细\n",
    "label_list_1 = list(data_set_1['一级行业'].unique())\n",
    "# 一级指标编号 用于模型训练\n",
    "label_list_1 = pd.DataFrame(label_list_1)\n",
    "label_1 = label_list_1.reset_index().rename(columns = {0:'一级行业','index':'label_1'})\n",
    "data_set_1 = pd.merge(data_set_1,label_1,on = '一级行业',how = 'left')\n",
    "# 二级指标明细\n",
    "label_list_2 = list(data_set_1['二级行业'].unique())\n",
    "# 二级指标编号 用于模型训练\n",
    "label_list_2 = pd.DataFrame(label_list_2)\n",
    "label_2 = label_list_2.reset_index().rename(columns = {0:'二级行业','index':'label_2'})\n",
    "data_set_1 = pd.merge(data_set_1,label_2,on = '二级行业',how = 'left')\n",
    "label_total = pd.merge(pd.merge(data_set_1[['label_1','label_2']].drop_duplicates(),label_1,on = 'label_1',how = 'left'),label_2,on = 'label_2',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39480c40-c87f-420f-a9d6-c74013036a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          股票代码   股票简称 公司简介  一级行业  二级行业  A/H GICS一级行业  GICS二级行业    GICS三级行业  \\\n",
      "140  000587.SZ  *ST金洲  NaN  商贸零售  珠宝首饰    0     可选消费  耐用消费品与服装  纺织品、服装与奢侈品   \n",
      "\n",
      "     wind一级  wind二级    wind三级      wind四级  label_1  label_2  \n",
      "140    6225  622520  62252030  6225203010       11       13  \n"
     ]
    }
   ],
   "source": [
    "#公司简介中有为nan的存在，先清除nan 再对简介进行分词\n",
    "\n",
    "print(data_set_1[data_set_1['公司简介'].isna()])\n",
    "data_set_1 =data_set_1[~data_set_1['公司简介'].isna()]\n",
    "data_set_1 = data_set_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae64db1-6bfd-4681-be9e-77fb6aa68834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.760 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 进行分词\n",
    "def trans_intr(x):\n",
    "    x = jieba.cut(x)\n",
    "    x = list(x)\n",
    "    return x\n",
    "data_set_1['公司简介(分词)'] = data_set_1['公司简介'].transform(trans_intr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3029f73-a3a6-4b35-926b-e9b3925949b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#去停用词\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "stoplist1 = stopwordslist('hit_stopwords.txt')\n",
    "stoplist2 = stopwordslist('cn_stopwords.txt')\n",
    "stoplist3 = stopwordslist('baidu_stopwords.txt')\n",
    "#经过对分词结果的评析 我们列出了另外一个词频表\n",
    "stoplist4 = ['公司', '企业', '产品', '生产', '研发', '技术', '中国', '服务', '主要', '国家', '业务', '行业',\n",
    "       '领域', '发展', '销售', '国内', '拥有', '提供', '客户', '制造', '高新技术', '中心', '年', '开发',\n",
    "       '认证', '品牌', '设计', '市场', '管理', '系统', '设备',  '包括', '创新', '专业', '全国',\n",
    "       '从事', '智能', '一家', '国际', '应用',  '经营', '成为', '产业', '工业', '解决方案',\n",
    "       '核心', '获得', '全球', '重点', '中', '质量', '新', '工程', '领先', '项目', '形成', '具有',\n",
    "       '单位', '自主', '先进', '目前', '科技', '综合', '集团', '建设', '能力', '平台', '优势', '运营',\n",
    "       '多年', '致力于', '研究', '管理体系', '先后', '装备', '主营业务', '安全', '实现', '投资',\n",
    "       '建立', '多项', '战略', '多个', '供应商', '体系', '合作', '系列', '大型', '认定', '国家级',\n",
    "       '专注', '基地', '一体', '城市','上市','更名','持续', '不断', '有限公司', '江苏省','坚持', '上市公司', '优秀','集',\n",
    "                       '完全',  '高端', '示范','方面', '荣获', '提升', '涵盖','国内外', '打造','配套', '布局', '浙江省',\n",
    "       '规模', '广东省', '模式', '最大', '积累', '积极', '评为', '控制','知名', '竞争', '整合','知名', '名牌', '标准', '驰名商标', '现代'\n",
    "             ,'品质', '产业化', '地区','广泛','竞争', '基础', '互联', '广泛', '知名', '覆盖','竞争力', '营销', '著名','世界', \n",
    "             '地区', '荣誉', '为主', '竞争', '商标','世界', '完善', '标准', '一体化', '工作', '资源', '水平']\n",
    "stoplist5 = ['上海', '依托', '区域','高效', '称号','控股','第一', \n",
    " '实验', '协会','成立','科学', '美国', '计划', '始终', '影响', '快速', '理念',\n",
    "  '重要','工艺', '荣誉称号','集成', '经验', '取得','日本', 'ISO9001', '相关','长期', '4.0']\n",
    "num = pd.DataFrame(data_set_1['公司简介(分词)'].explode().unique())\n",
    "stoplist6 = num[num[0].str.contains('^[0-9]*$')][0].to_list()\n",
    "stoplist7=num[num[0].str.contains('^[A-Z]*$')][0].to_list()\n",
    "stoplist8=num[num[0].str.contains('^[a-z]*$')][0].to_list()\n",
    "\n",
    "\n",
    "stop_word_list_general = stoplist1+stoplist2+stoplist3+stoplist4+stoplist5+stoplist6+stoplist7+stoplist8\n",
    "stop_word_list_general = list(set(stop_word_list_general))\n",
    "def delete_stop_word_general(list1):\n",
    "    list_done  = []\n",
    "    for i in list1:\n",
    "        if i not in stop_word_list_general:\n",
    "            list_done.append(i)\n",
    "    return list_done\n",
    "data_set_1['公司简介(分词) 去 停用'] = data_set_1['公司简介(分词)'].transform(delete_stop_word_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0639d4bd-a291-4e53-85fb-b59104c04269",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_selection = pd.DataFrame(data_set_1.groupby(['二级行业'])['公司简介(分词) 去 停用'])\n",
    "keywords_selection[2] = keywords_selection[1].apply(lambda x:','.join(x.explode().to_list()))\n",
    "keywords_selection[3] = keywords_selection[1].apply(lambda x:','.join(list(set(x.explode().to_list()))))\n",
    "keywords_selection['keywords'] = pd.Series()\n",
    "for i in range(len(keywords_selection)):\n",
    "    input_1 = keywords_selection[1].iloc[i]\n",
    "    one_sector = pd.DataFrame(input_1)\n",
    "    one_sector['merge'] = one_sector['公司简介(分词) 去 停用'].apply(lambda x:','.join(list(set(x))))\n",
    "    tf = pd.DataFrame(index = one_sector['公司简介(分词) 去 停用'].explode().unique()).reset_index()\n",
    "    tf = tf[tf['index'].apply(lambda x:len(x)) >=2]\n",
    "    tf['tf'] = tf['index'].apply(lambda x:one_sector['merge'].str.contains(x).sum()/len(one_sector))\n",
    "    tf['idf'] = tf['index'].apply(lambda x:len(keywords_selection)/(keywords_selection[3].str.contains(x).sum()+1))\n",
    "    tf['tf-idf'] = tf['tf']/tf['idf']\n",
    "    keywords_selection['keywords'].iloc[i] = tf.sort_values('tf-idf')['index'].tail(20).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ada0bc4-ce5e-4ca0-8803-a663099aa4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#关键词整合\n",
    "keywords_list = keywords_selection.groupby(0)['keywords'].sum().explode().unique()\n",
    "def trans2vec(x):\n",
    "    return pd.merge(pd.DataFrame(pd.DataFrame(index = keywords_list)),\n",
    "    pd.DataFrame(x).reset_index().groupby(0).count(),\n",
    "    left_index = True,\n",
    "    right_index = True,\n",
    "    how = 'left').fillna(0)['index'].to_list()\n",
    "trans_result = pd.DataFrame(data_set_1['公司简介(分词) 去 停用'].transform(trans2vec).to_list())\n",
    "trans_result.columns = keywords_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e908e228-0288-4b28-93c8-55b8738e259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = pd.merge(data_set_1,trans_result,how = 'left',left_index = True,right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf1acb8-22b1-4ae9-b2c9-59b3cb2513d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['GICS一级行业', 'GICS二级行业', 'GICS三级行业']:\n",
    "    data_set_1=pd.merge(data_set_1,\n",
    "         pd.DataFrame(list(data_set_1[i].unique())).reset_index().rename(columns = {0:i,'index':i+'label'}),\n",
    "         on = i,\n",
    "         how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3d0b8bd-1787-47e0-8a89-cc716aae8274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_list = list(keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f814c07-3acd-4d6c-a3d9-3538bf52f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "#一级的预测效果90% 二级如果用和一级一样的指标只有60% \n",
    "#因此我们先预测一级 把预测的模型也加入第二部的预测。因为一级只能对应一些行业 能够提高预测准确率\n",
    "train_data_set  = data_set_1[data_set_1['A/H'] == 0]\n",
    "test_data_set = data_set_1[data_set_1['A/H'] == 1]\n",
    "# test_data_set =  test_data_set[~test_data_set['股票代码'].isin(test_data_set_sample['股票代码'])]\n",
    "X_train = train_data_set[['wind一级', 'wind二级', 'wind三级','wind四级','GICS一级行业label', 'GICS二级行业label','GICS三级行业label']+list(keywords_list)]\n",
    "y_train = train_data_set['label_1'].copy()\n",
    "X_test = test_data_set[['wind一级', 'wind二级', 'wind三级','wind四级','GICS一级行业label', 'GICS二级行业label','GICS三级行业label']+list(keywords_list)]\n",
    "y_test = test_data_set['label_1'].copy()\n",
    "clf1 = xgb.XGBClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "test_predict = clf1.predict(X_test)\n",
    "confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)\n",
    "print(np.trace(confusion_matrix_result)/len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a5c759f-fdb3-4b45-a20a-0efe4d3c2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_first = list(X_train.columns)\n",
    "X_train['pre'] = clf1.predict(X_train)\n",
    "X_test['pre'] = clf1.predict(X_test)\n",
    "y_train = train_data_set['label_2'].copy()\n",
    "y_test = test_data_set['label_2'].copy()\n",
    "#将一级指标对应的二级信息加入数据集中\n",
    "secodary = pd.get_dummies(label_total['label_2'])\n",
    "secodary.index = label_total['label_1']\n",
    "secodary = secodary.reset_index().groupby('label_1').sum()\n",
    "secodary = secodary.reset_index().rename(columns = {'label_1':'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698fea61-7986-4273-8172-ed6c9f976a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train,secodary,on = 'pre',how = 'left')\n",
    "X_test = pd.merge(X_test,secodary,on = 'pre',how = 'left')\n",
    "input_for_secode = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affcd999-de5e-493e-9287-bd35740312ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "clf2 = xgb.XGBClassifier()\n",
    "clf2.fit(X_train,y_train)\n",
    "test_predict = clf2.predict(X_test)\n",
    "confusion_matrix_result = metrics.confusion_matrix(test_predict,y_test)\n",
    "print(np.trace(confusion_matrix_result)/len(test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa094cd1-6bff-46b6-b3b7-3d99e5a91ac4",
   "metadata": {},
   "source": [
    "计算最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b762bc29-57a5-4748-99ae-c8c15fea9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predict_set.sort_values('股票代码')\n",
    "X_pre = x[['股票代码','GICS一级行业', 'GICS二级行业','GICS三级行业','wind一级', 'wind二级', 'wind三级','wind四级']]\n",
    "x['公司简介(分词)'] = x['公司简介'].transform(trans_intr)\n",
    "x['公司简介(分词) 去 停用'] = x['公司简介(分词)'].transform(delete_stop_word_general)\n",
    "trans_result_for_test = pd.DataFrame(x['公司简介(分词) 去 停用'].transform(trans2vec).to_list())\n",
    "trans_result_for_test.columns = keywords_list\n",
    "X_pre = pd.merge(X_pre,trans_result_for_test,how = 'left',left_index = True,right_index = True)\n",
    "for i in ['GICS一级行业', 'GICS二级行业', 'GICS三级行业']:\n",
    "    X_pre=pd.merge(X_pre,\n",
    "         pd.DataFrame(list(data_set_1[i].unique())).reset_index().rename(columns = {0:i,'index':i+'label'}),\n",
    "         on = i,\n",
    "         how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6116ca-c389-4da7-a4da-aec9b5b0acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#一级预测\n",
    "output_result_1 = clf1.predict(X_pre[input_for_first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04900568",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_pre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m output_result_1 \n\u001b[1;32m      2\u001b[0m X_pre \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(X_pre,secodary,on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m,how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m output_result_2 \u001b[38;5;241m=\u001b[39m clf1\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_for_secode\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144] not in index'"
     ]
    }
   ],
   "source": [
    "X_pre['pre'] = output_result_1 \n",
    "X_pre = pd.merge(X_pre,secodary,on = 'pre',how = 'left')\n",
    "output_result_2 = clf1.predict(X_pre[input_for_secode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e116b6c3-1601-4482-9c3b-993dcbdd8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果输出\n",
    "output_result_for_2 = pd.merge(pd.DataFrame(output_result_2,X_pre['股票代码']).reset_index().rename(columns = {0:'label_2'}),\n",
    "label_total,\n",
    "on = 'label_2',\n",
    "how = 'left')[['股票代码','二级行业']]\n",
    "\n",
    "output_result_for_1 = pd.merge(pd.DataFrame(output_result_1,X_pre['股票代码']).reset_index().rename(columns = {0:'label_1'}),\n",
    "label_total,\n",
    "on = 'label_1',\n",
    "how = 'left')[['股票代码','一级行业']]\n",
    "output = pd.merge(output_result_for_2,output_result_for_1,on = '股票代码',how = 'left').drop_duplicates()\n",
    "output = output[['股票代码','一级行业','二级行业']].append(predict_set_have_label[['股票代码','一级行业','二级行业']])\n",
    "predict_set = pd.read_excel('数据.xlsx',sheet_name ='待分类港股标的')\n",
    "output = pd.merge(predict_set.drop(['一级行业','二级行业'],axis = 1),output,on = '股票代码',how = 'left')[predict_set.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21ffb096-51a9-4908-8ed1-20ca3fd6f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel('预测结果.xlsx',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
